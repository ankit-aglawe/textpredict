{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#advanced-text-classification-with-transformer-models","title":"Advanced Text Classification with Transformer Models","text":"<p>TextPredict is a powerful Python package designed for various text analysis and prediction tasks using advanced NLP models. It simplifies the process of performing sentiment analysis, emotion detection, zero-shot classification, named entity recognition (NER), and more. Built on top of Hugging Face's Transformers, TextPredict allows seamless integration with pre-trained models or custom models for specific tasks.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Sentiment Analysis: Determine the sentiment of text (positive, negative, neutral).</li> <li>Emotion Detection: Identify emotions such as happiness, sadness, anger, etc.</li> <li>Zero-Shot Classification: Classify text into custom categories without additional training.</li> <li>Named Entity Recognition (NER): Extract entities like names, locations, and organizations from text.</li> <li>Sequence Classification: Fine-tune models for custom classification tasks.</li> <li>Token Classification: Classify tokens within text for tasks like NER.</li> <li>Sequence-to-Sequence (Seq2Seq): Perform tasks like translation and summarization.</li> <li>Model Comparison: Evaluate and compare multiple models on the same dataset.</li> <li>Explainability: Understand model predictions through feature importance analysis.</li> <li>Text Cleaning: Utilize utility functions for preprocessing text data.</li> </ul>"},{"location":"#supported-tasks","title":"Supported Tasks","text":"<ul> <li>Sentiment Analysis</li> <li>Emotion Detection</li> <li>Zero-Shot Classification</li> <li>Named Entity Recognition (NER)</li> <li>Sequence Classification</li> <li>Token Classification</li> <li>Sequence-to-Sequence (Seq2Seq)</li> </ul>"},{"location":"api_reference/","title":"API Reference","text":"<p>Sure, I can organize the API reference using the format you've suggested. Here is the complete API reference with each class and method listed:</p>"},{"location":"api_reference/#api-reference","title":"API Reference","text":""},{"location":"api_reference/#textpredictinitialize","title":"<code>textpredict.initialize</code>","text":"<p>Initialize the TextPredict model for a specific task.</p>"},{"location":"api_reference/#parameters","title":"Parameters","text":"<ul> <li><code>task</code> (str): The task to perform (e.g., 'sentiment', 'emotion', 'zeroshot', 'ner', 'sequence_classification', 'token_classification', 'seq2seq').</li> <li><code>device</code> (str, optional): The device to run the model on. Defaults to 'cpu'.</li> <li><code>model_name</code> (str, optional): The model name. Defaults to None.</li> <li><code>source</code> (str, optional): The source of the model ('huggingface' or 'local'). Defaults to 'huggingface'.</li> </ul>"},{"location":"api_reference/#returns","title":"Returns","text":"<p>An initialized TextPredict model.</p>"},{"location":"api_reference/#textpredicttextpredictanalyze","title":"<code>textpredict.TextPredict.analyze</code>","text":"<p>Analyze the provided texts using the initialized model.</p>"},{"location":"api_reference/#parameters_1","title":"Parameters","text":"<ul> <li><code>text</code> (str or list of str): The text(s) to analyze.</li> <li><code>return_probs</code> (bool, optional): Whether to return probabilities along with predictions. Defaults to False.</li> <li><code>candidate_labels</code> (list of str, optional): The candidate labels for zero-shot classification. Defaults to None.</li> </ul>"},{"location":"api_reference/#returns_1","title":"Returns","text":"<p>Analysis results for the provided texts.</p>"},{"location":"api_reference/#textpredictsequenceclassificationtrainer","title":"<code>textpredict.SequenceClassificationTrainer</code>","text":"<p>Trainer class for sequence classification models.</p>"},{"location":"api_reference/#parameters_2","title":"Parameters","text":"<ul> <li><code>model_name</code> (str): The name of the model to use.</li> <li><code>output_dir</code> (str): The directory to save the trained model.</li> <li><code>config</code> (dict, optional): Configuration dictionary. Defaults to None.</li> <li><code>device</code> (str, optional): The device to run the model on. Defaults to 'cpu'.</li> </ul>"},{"location":"api_reference/#methods","title":"Methods","text":"<ul> <li><code>textpredict.SequenceClassificationTrainer.train(from_checkpoint=True)</code>: Train the model.</li> </ul> <p>Parameters:   - <code>from_checkpoint</code> (bool, optional): Whether to train from a checkpoint. Defaults to <code>True</code>.</p> <ul> <li> <p><code>textpredict.SequenceClassificationTrainer.save()</code>: Save the trained model.</p> </li> <li> <p><code>textpredict.SequenceClassificationTrainer.evaluate(test_dataset, evaluation_config=None)</code>: Evaluate the model on the test dataset.</p> </li> </ul> <p>Parameters:   - <code>test_dataset</code> (Dataset): The dataset to evaluate the model on.   - <code>evaluation_config</code> (dict, optional): Configuration for evaluation. Defaults to <code>None</code>.</p>"},{"location":"api_reference/#example","title":"Example","text":"<pre><code>from textpredict import SequenceClassificationTrainer\ntrainer = SequenceClassificationTrainer(model_name='bert-base-uncased', output_dir='./model')\ntrainer.train()\ntrainer.save()\nresults = trainer.evaluate(test_dataset)\nprint(results)\n</code></pre>"},{"location":"api_reference/#textpredictseq2seqtrainer","title":"<code>textpredict.Seq2seqTrainer</code>","text":"<p>Trainer class for sequence-to-sequence models.</p>"},{"location":"api_reference/#parameters_3","title":"Parameters","text":"<ul> <li><code>model_name</code> (str): The name of the model to use.</li> <li><code>output_dir</code> (str): The directory to save the trained model.</li> <li><code>config</code> (dict, optional): Configuration dictionary. Defaults to None.</li> <li><code>device</code> (str, optional): The device to run the model on. Defaults to 'cpu'.</li> </ul>"},{"location":"api_reference/#methods_1","title":"Methods","text":"<ul> <li><code>textpredict.Seq2seqTrainer.train(from_checkpoint=False)</code>: Train the model.</li> </ul> <p>Parameters:   - <code>from_checkpoint</code> (bool, optional): Whether to train from a checkpoint. Defaults to <code>False</code>.</p> <ul> <li> <p><code>textpredict.Seq2seqTrainer.save()</code>: Save the trained model.</p> </li> <li> <p><code>textpredict.Seq2seqTrainer.evaluate(test_dataset, evaluation_config=None)</code>: Evaluate the model on the test dataset.</p> </li> </ul> <p>Parameters:   - <code>test_dataset</code> (Dataset): The dataset to evaluate the model on.   - <code>evaluation_config</code> (dict, optional): Configuration for evaluation. Defaults to <code>None</code>.</p>"},{"location":"api_reference/#example_1","title":"Example","text":"<pre><code>from textpredict import Seq2seqTrainer\ntrainer = Seq2seqTrainer(model_name='t5-small', output_dir='./model')\ntrainer.train()\ntrainer.save()\nresults = trainer.evaluate(test_dataset)\nprint(results)\n</code></pre>"},{"location":"api_reference/#textpredicttokenclassificationtrainer","title":"<code>textpredict.TokenClassificationTrainer</code>","text":"<p>Trainer class for token classification models.</p>"},{"location":"api_reference/#parameters_4","title":"Parameters","text":"<ul> <li><code>model_name</code> (str): The name of the model to use.</li> <li><code>output_dir</code> (str): The directory to save the trained model.</li> <li><code>config</code> (dict, optional): Configuration dictionary. Defaults to None.</li> <li><code>device</code> (str, optional): The device to run the model on. Defaults to 'cpu'.</li> </ul>"},{"location":"api_reference/#methods_2","title":"Methods","text":"<ul> <li><code>textpredict.TokenClassificationTrainer.train(from_checkpoint=False)</code>: Train the model.</li> </ul> <p>Parameters:   - <code>from_checkpoint</code> (bool, optional): Whether to train from a checkpoint. Defaults to <code>False</code>.</p> <ul> <li> <p><code>textpredict.TokenClassificationTrainer.save()</code>: Save the trained model.</p> </li> <li> <p><code>textpredict.TokenClassificationTrainer.evaluate(test_dataset, evaluation_config=None)</code>: Evaluate the model on the test dataset.</p> </li> </ul> <p>Parameters:   - <code>test_dataset</code> (Dataset): The dataset to evaluate the model on.   - <code>evaluation_config</code> (dict, optional): Configuration for evaluation. Defaults to <code>None</code>.</p>"},{"location":"api_reference/#example_2","title":"Example","text":"<pre><code>from textpredict import TokenClassificationTrainer\ntrainer = TokenClassificationTrainer(model_name='bert-base-uncased', output_dir='./model')\ntrainer.train()\ntrainer.save()\nresults = trainer.evaluate(test_dataset)\nprint(results)\n</code></pre>"},{"location":"api_reference/#textpredictsequenceclassificationevaluator","title":"<code>textpredict.SequenceClassificationEvaluator</code>","text":"<p>Evaluator class for sequence classification models.</p>"},{"location":"api_reference/#parameters_5","title":"Parameters","text":"<ul> <li><code>model_name</code> (str): The name of the model to evaluate.</li> <li><code>device</code> (str, optional): The device to run the model on. Defaults to 'cpu'.</li> <li><code>evaluation_config</code> (dict, optional): Configuration dictionary. Defaults to None.</li> </ul>"},{"location":"api_reference/#methods_3","title":"Methods","text":"<ul> <li> <p><code>textpredict.SequenceClassificationEvaluator.evaluate()</code>: Evaluate the model on the provided dataset.</p> </li> <li> <p><code>textpredict.SequenceClassificationEvaluator.get_detailed_metrics()</code>: Retrieve detailed evaluation metrics.</p> </li> <li> <p><code>textpredict.SequenceClassificationEvaluator.save_results(file_path)</code>: Save evaluation results to a file.</p> </li> </ul>"},{"location":"api_reference/#example_3","title":"Example","text":"<pre><code>from textpredict import SequenceClassificationEvaluator\nevaluator = SequenceClassificationEvaluator(model_name='./model')\nresults = evaluator.evaluate(test_dataset)\nprint(results)\n</code></pre>"},{"location":"api_reference/#textpredictseq2seqevaluator","title":"<code>textpredict.Seq2seqEvaluator</code>","text":"<p>Evaluator class for sequence-to-sequence models.</p>"},{"location":"api_reference/#parameters_6","title":"Parameters","text":"<ul> <li><code>model_name</code> (str): The name of the model to evaluate.</li> <li><code>device</code> (str, optional): The device to run the model on. Defaults to 'cpu'.</li> <li><code>evaluation_config</code> (dict, optional): Configuration dictionary. Defaults to None.</li> </ul>"},{"location":"api_reference/#methods_4","title":"Methods","text":"<ul> <li> <p><code>textpredict.Seq2seqEvaluator.evaluate()</code>: Evaluate the model on the provided dataset.</p> </li> <li> <p><code>textpredict.Seq2seqEvaluator.get_detailed_metrics()</code>: Retrieve detailed evaluation metrics.</p> </li> <li> <p><code>textpredict.Seq2seqEvaluator.save_results(file_path)</code>: Save evaluation results to a file.</p> </li> </ul>"},{"location":"api_reference/#example_4","title":"Example","text":"<pre><code>from textpredict import Seq2seqEvaluator\nevaluator = Seq2seqEvaluator(model_name='./model')\nresults = evaluator.evaluate(test_dataset)\nprint(results)\n</code></pre>"},{"location":"api_reference/#textpredicttokenclassificationevaluator","title":"<code>textpredict.TokenClassificationEvaluator</code>","text":"<p>Evaluator class for token classification models.</p>"},{"location":"api_reference/#parameters_7","title":"Parameters","text":"<ul> <li><code>model_name</code> (str): The name of the model to evaluate.</li> <li><code>device</code> (str, optional): The device to run the model on. Defaults to 'cpu'.</li> <li><code>evaluation_config</code> (dict, optional): Configuration dictionary. Defaults to None.</li> </ul>"},{"location":"api_reference/#methods_5","title":"Methods","text":"<ul> <li> <p><code>textpredict.TokenClassificationEvaluator.evaluate()</code>: Evaluate the model on the provided dataset.</p> </li> <li> <p><code>textpredict.TokenClassificationEvaluator.get_detailed_metrics()</code>: Retrieve detailed evaluation metrics.</p> </li> <li> <p><code>textpredict.TokenClassificationEvaluator.save_results(file_path)</code>: Save evaluation results to a file.</p> </li> </ul>"},{"location":"api_reference/#example_5","title":"Example","text":"<pre><code>from textpredict import TokenClassificationEvaluator\nevaluator = TokenClassificationEvaluator(model_name='./model')\nresults = evaluator.evaluate(test_dataset)\nprint(results)\n</code></pre>"},{"location":"api_reference/#textpredictbenchmarking","title":"<code>textpredict.Benchmarking</code>","text":"<p>Class for benchmarking models.</p>"},{"location":"api_reference/#parameters_8","title":"Parameters","text":"<ul> <li><code>model_name</code> (str): The name of the model to use.</li> <li><code>device</code> (str, optional): The device to run the model on. Defaults to 'cpu'.</li> </ul>"},{"location":"api_reference/#methods_6","title":"Methods","text":"<ul> <li> <p><code>textpredict.Benchmarking.benchmark(dataset)</code>: Benchmark the model using the provided dataset.</p> </li> <li> <p><code>textpredict.Benchmarking.measure_inference_time(dataset)</code>: Measure inference time on the provided dataset.</p> </li> <li> <p><code>textpredict.Benchmarking.measure_memory_usage(dataset)</code>: Measure memory usage on the provided dataset.</p> </li> </ul>"},{"location":"api_reference/#example_6","title":"Example","text":"<pre><code>from textpredict import Benchmarking\nbenchmark = Benchmarking(model_name='bert-base-uncased')\nmetrics = benchmark.benchmark(test_dataset)\ninference_time = benchmark.measure_inference_time(test_dataset)\nmemory_usage = benchmark.measure_memory_usage(test_dataset)\nprint(metrics, inference_time, memory_usage)\n</code></pre>"},{"location":"api_reference/#textpredictexplainability","title":"<code>textpredict.Explainability</code>","text":"<p>Class for model explainability and feature importance.</p>"},{"location":"api_reference/#parameters_9","title":"Parameters","text":"<ul> <li><code>model_name</code> (str): The name of the model to use.</li> <li><code>task</code> (str): The task to perform.</li> <li><code>device</code> (str, optional): The device to run the model on. Defaults to 'cpu'.</li> </ul>"},{"location":"api_reference/#methods_7","title":"Methods","text":"<ul> <li><code>textpredict.Explainability.feature_importance(text)</code>: Get feature importance for the given text.</li> </ul>"},{"location":"api_reference/#example_7","title":"Example","text":"<pre><code>from textpredict import initialize, Explainability\n\n# Initialize the predictor\npredictor = initialize(task='sentiment', device='cpu', model_name='bert-base-uncased')\n\n# Explainability instance\nexplain = Explainability(model_name='bert-base-uncased', task='sentiment')\n\n# Get feature importance\nimportance = explain.feature_importance(\"This is a great product!\")\nprint(importance)\n</code></pre>"},{"location":"examples/","title":"Examples","text":"<p>This section provides example scripts to illustrate how to use various functionalities of the <code>textpredict</code> package.</p>"},{"location":"examples/#simple-text-prediction","title":"Simple Text Prediction","text":"<p>The following example demonstrates how to use the <code>textpredict</code> package to perform simple sentiment analysis and emotion detection.</p> <pre><code>from datasets import load_dataset\nimport textpredict as tp\n\n# Function to test simple prediction using default model\ndef text_simple_prediction():\n    # Sentiment analysis\n    texts = [\"I love this product!\", \"I love this product!\"]\n    model = tp.initialize(task=\"sentiment\")\n    result = model.analyze(texts, return_probs=False)\n    print(f\"Simple Prediction Result: {result}\")\n\n    # Emotion detection\n    texts = [\"I am happy today\", \"I am happy today\"]\n    model = tp.initialize(task=\"emotion\")\n    result = model.analyze(texts, return_probs=False)\n    print(f\"Emotion Prediction Result: {result}\")\n\nif __name__ == \"__main__\":\n    text_simple_prediction()\n</code></pre>"},{"location":"examples/#sequence-classification-training","title":"Sequence Classification Training","text":"<p>The following example demonstrates how to use the <code>SequenceClassificationTrainer</code> class to train a sequence classification model.</p> <pre><code>from datasets import load_dataset\nimport textpredict as tp\n\n# Function to test sequence classification trainer\ndef sequence_classification_training():\n    dataset = load_dataset('imdb')\n    trainer = tp.SequenceClassificationTrainer(model_name='bert-base-uncased', output_dir='./model', config=None, device='cpu')\n    trainer.train_dataset = dataset['train']\n    trainer.val_dataset = dataset['test']\n    trainer.train()\n    trainer.save()\n    results = trainer.evaluate(dataset['test'])\n    print(f\"Training Results: {results}\")\n\nif __name__ == \"__main__\":\n    sequence_classification_training()\n</code></pre>"},{"location":"examples/#explainability","title":"Explainability","text":"<p>The following example demonstrates how to use the <code>Explainability</code> class to get feature importance for a given text.</p> <pre><code>from textpredict import initialize, Explainability\n\n# Initialize the predictor\npredictor = initialize(task='sentiment', device='cpu', model_name='bert-base-uncased')\n\n# Explainability instance\nexplain = Explainability(model_name='bert-base-uncased', task='sentiment')\n\n# Get feature importance\nimportance = explain.feature_importance(\"This is a great product!\")\nprint(importance)\n</code></pre>"},{"location":"examples/#benchmarking","title":"Benchmarking","text":"<p>The following example demonstrates how to use the <code>Benchmarking</code> class to benchmark a model.</p> <pre><code>from textpredict import Benchmarking\nfrom datasets import load_dataset\n\ndef benchmark_model():\n    dataset = load_dataset('imdb', split='test')\n    benchmark = Benchmarking(model_name='bert-base-uncased')\n    metrics = benchmark.benchmark(dataset)\n    inference_time = benchmark.measure_inference_time(dataset)\n    memory_usage = benchmark.measure_memory_usage(dataset)\n    print(metrics, inference_time, memory_usage)\n\nif __name__ == \"__main__\":\n    benchmark_model()\n</code></pre>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#installation","title":"Installation","text":"<p>You can install the package via pip:</p> <pre><code>pip install textpredict\n</code></pre>"},{"location":"usage/#quick-start","title":"Quick Start","text":""},{"location":"usage/#initialization-and-simple-prediction","title":"Initialization and Simple Prediction","text":"<pre><code>import textpredict as tp\n\n# Initialize for sentiment analysis\nmodel = tp.initialize(task=\"sentiment\")\ntexts = [\"I love this product!\", \"I hate this product!\"]\nresult = model.analyze(texts, return_probs=False)\nprint(f\"Sentiment Prediction Result: {result}\")\n</code></pre>"},{"location":"usage/#using-pre-trained-models-from-hugging-face","title":"Using Pre-trained Models from Hugging Face","text":"<pre><code>model = tp.initialize(\n    task=\"sentiment\",\n    device=\"cpu\",\n    model_name=\"AnkitAI/reviews-roberta-base-sentiment-analysis\",\n    source=\"huggingface\",\n)\ntext = \"I love this product!\"\nresult = model.analyze(text, return_probs=True)\nprint(f\"Sentiment Prediction Result: {result}\")\n</code></pre>"},{"location":"usage/#using-models-from-local-directory","title":"Using Models from Local Directory","text":"<pre><code>model = tp.initialize(\n    task=\"sentiment\",\n    model_name=\"./results\",\n    source=\"local\",\n)\ntext = \"I love this product!\"\nresult = model.analyze(text, return_probs=True)\nprint(f\"Sentiment Prediction Result: {result}\")\n</code></pre>"},{"location":"usage/#training-a-model","title":"Training a Model","text":"<pre><code>import textpredict as tp\nfrom datasets import load_dataset\n\n# Load dataset\ntrain_data = load_dataset(\"imdb\", split=\"train[:10]\")\nval_data = load_dataset(\"imdb\", split=\"test[:10]\")\n\n# Initialize and train the model\ntrainer = tp.SequenceClassificationTrainer(\n    model_name=\"bert-base-uncased\",\n    output_dir=\"./results\",\n    train_dataset=train_data,\n    val_dataset=val_data\n)\ntrainer.train()\n\n# Save the trained model\ntrainer.save()\n\n# Evaluate the model\nmetrics = trainer.evaluate(test_dataset=val_data)\nprint(f\"Evaluation Metrics: {metrics}\")\n</code></pre>"}]}